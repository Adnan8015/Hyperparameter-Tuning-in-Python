{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introducing Grid Search**"
      ],
      "metadata": {
        "id": "iz-b8uAUlv9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxfyDf5GlrY_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "Build a function that takes two parameters called learning_rate and max_depth for the learning rate and maximum depth.\n",
        "Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.\n",
        "Have the function return the results of that model and the chosen hyperparameters (learning_rate and max_depth)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Create the function\n",
        "def gbm_grid_search(learning_rate, max_depth):\n",
        "\n",
        "\t# Create the model\n",
        "    model = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=max_depth)\n",
        "\n",
        "    # Use the model to make predictions\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "    # Return the hyperparameters and score\n",
        "    return([learning_rate, max_depth, accuracy_score(y_test, predictions)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Write a for-loop to test the values (0.01, 0.1, 0.5) for the learning_rate and (2, 4, 6) for the max_depth using the function created gbm_grid_search and print the results\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Create the relevant lists\n",
        "results_list = []\n",
        "learn_rate_list = [.01, .1, .5]\n",
        "max_depth_list = [2, 4, 6]\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        results_list.append(gbm_grid_search(learn_rate,max_depth))\n",
        "\n",
        "# Print the results\n",
        "print(results_list)"
      ],
      "metadata": {
        "id": "Dl_PrWEOl1I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search with Scikit Learn**"
      ],
      "metadata": {
        "id": "LrAvL4dnl7Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "GridSearchCV with Scikit Learn\n",
        "The GridSearchCV module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a GridSearchCV object with certain parameters.\n",
        "\n",
        "The desired options are:\n",
        "\n",
        "A Random Forest Estimator, with the split criterion as 'entropy'\n",
        "5-fold cross validation\n",
        "The hyperparameters max_depth (2, 4, 8, 15) and max_features ('auto' vs 'sqrt')\n",
        "Use roc_auc to score the models\n",
        "Use 4 cores for processing in parallel\n",
        "Ensure you refit the best model and return training scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Create a Random Forest Classifier with specified criterion\n",
        "rf_class = RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "# Create the parameter grid\n",
        "param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto' , 'sqrt']}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_rf_class = GridSearchCV(\n",
        "    estimator=rf_class,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=4,\n",
        "    cv=5,\n",
        "    refit=True, return_train_score=True)\n",
        "print(grid_rf_class)"
      ],
      "metadata": {
        "id": "6Yp_f4b3l8kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding a grid search output**"
      ],
      "metadata": {
        "id": "IlS9w3oQmDBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Read the cv_results_ property of the grid_rf_class GridSearchCV object into a data frame & print the whole thing out to inspect.\n",
        "Extract & print the singular column containing a dictionary of all hyperparameters used in each iteration of the grid search.\n",
        "Extract & print the row that had the best mean test score by indexing using the rank_test_score column.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Read the cv_results property into a dataframe & print it out\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "print(cv_results_df)\n",
        "\n",
        "# Extract and print the column with a dictionary of hyperparameters used\n",
        "column = cv_results_df.loc[:, [ \"params\"]]\n",
        "print(column)\n",
        "\n",
        "# Extract and print the row that had the best mean test score\n",
        "best_row = cv_results_df[cv_results_df[\"rank_test_score\"] == 1 ]\n",
        "print(best_row)"
      ],
      "metadata": {
        "id": "2T1E6QrrmEkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Extract and print out the ROC_AUC score from the best performing square in grid_rf_class.\n",
        "Create a variable from the best-performing row by indexing into cv_results_df.\n",
        "Create a variable, best_n_estimators by extracting the n_estimators parameter from the best-performing square in grid_rf_class and print it out.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Print out the ROC_AUC score from the best-performing square\n",
        "best_score = grid_rf_class.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Create a variable from the row related to the best-performing square\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
        "print(best_row)\n",
        "\n",
        "# Get the n_estimators parameter from the best-performing square and print\n",
        "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
        "print(best_n_estimators)"
      ],
      "metadata": {
        "id": "nbHSbAt5mIUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Check the type of the best_estimator_ property.\n",
        "Use the best_estimator_ property to make predictions on our test set.\n",
        "Generate a confusion matrix and ROC_AUC score from our predictions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# See what type of object the best_estimator_ property is\n",
        "print(type(grid_rf_class.best_estimator_))\n",
        "\n",
        "# Create an array of predictions directly using the best_estimator_ property\n",
        "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
        "\n",
        "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Now create a confusion matrix\n",
        "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Get the ROC-AUC score\n",
        "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
      ],
      "metadata": {
        "id": "nzw6fRzWmI8t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}