{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjdurFGhOCu"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "Create a list of the original column names used in the training DataFrame.\n",
        "Extract the coefficients of the logistic regression estimator.\n",
        "Create a DataFrame of coefficients and variable names & view it.\n",
        "Print out the top 3 'positive' variables based on the coefficient size.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Create a list of original variable names from the training DataFrame\n",
        "original_variables = list(X_train.columns)\n",
        "\n",
        "# Extract the coefficients of the logistic regression estimator\n",
        "model_coefficients = log_reg_clf.coef_[0]\n",
        "\n",
        "# Create a dataframe of the variables and coefficients & print it out\n",
        "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
        "print(coefficient_df)\n",
        "\n",
        "# Print out the top 3 positive variables\n",
        "top_three_df = coefficient_df.sort_values(by=[\"Coefficient\"], axis=0, ascending=False)[0:3]\n",
        "print(top_three_df)\n",
        "\n",
        "\"\"\"\n",
        " Variable  Coefficient\n",
        "0     LIMIT_BAL   -3.926e-06\n",
        "1           AGE   -3.170e-06\n",
        "2         PAY_0    2.189e-07\n",
        "3         PAY_2    1.129e-07\n",
        "4         PAY_3    1.110e-07\n",
        "5         PAY_4    1.264e-07\n",
        "6         PAY_5    1.291e-07\n",
        "7         PAY_6    1.235e-07\n",
        "8     BILL_AMT1   -7.001e-06\n",
        "9     BILL_AMT2   -4.343e-06\n",
        "10    BILL_AMT3    4.402e-06\n",
        "11    BILL_AMT4    1.599e-05\n",
        "12    BILL_AMT5    3.373e-06\n",
        "13    BILL_AMT6   -2.527e-06\n",
        "14     PAY_AMT1   -6.498e-05\n",
        "15     PAY_AMT2   -9.547e-05\n",
        "16     PAY_AMT3   -5.436e-05\n",
        "17     PAY_AMT4   -3.596e-05\n",
        "18     PAY_AMT5   -3.400e-05\n",
        "19     PAY_AMT6    3.083e-06\n",
        "20        SEX_2   -7.633e-08\n",
        "21  EDUCATION_1   -7.142e-09\n",
        "22  EDUCATION_2   -6.246e-08\n",
        "23  EDUCATION_3   -2.333e-08\n",
        "24  EDUCATION_4   -1.172e-09\n",
        "25  EDUCATION_5   -2.403e-09\n",
        "26  EDUCATION_6   -2.595e-10\n",
        "27   MARRIAGE_1   -2.480e-08\n",
        "28   MARRIAGE_2   -7.474e-08\n",
        "29   MARRIAGE_3    2.855e-09\n",
        "     Variable  Coefficient\n",
        "11  BILL_AMT4    1.599e-05\n",
        "10  BILL_AMT3    4.402e-06\n",
        "12  BILL_AMT5    3.373e-06\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters\n",
        " Overview**"
      ],
      "metadata": {
        "id": "lJwGFXyghYGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Print out the hyperparameters of the existing random forest classifier by printing the estimator and then create a confusion matrix and accuracy score from it.\n",
        "\n",
        "Assess the performance of the new random forest classifier. Create the confusion matrix and accuracy score and print them out\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "rf_clf_old = RandomForestClassifier()\n",
        "\n",
        "# Print out the random forest hyperparameters\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  \tconfusion_matrix(y_test, rf_old_predictions),\n",
        "  \taccuracy_score(y_test, rf_old_predictions)))\n",
        "\n",
        "# Create a new random forest classifier with better hyperparamaters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Assess the new model (using new predictions!)\n",
        "print(\"Confusion Matrix: \\n\\n\", confusion_matrix(y_test, rf_new_predictions))\n",
        "print(\"Accuracy Score: \\n\\n\", accuracy_score(y_test, rf_new_predictions))"
      ],
      "metadata": {
        "id": "tubklalwhSyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Build a knn estimator for the following values of n_neighbors [5,10,20].\n",
        "Fit each to the training data and produce predictions.\n",
        "Get an accuracy score for each model and print them out.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Build a knn estimator for each value of n_neighbours\n",
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
        "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "# Fit each to the training data & produce predictions\n",
        "knn_5_predictions = knn_5.fit(X_train, y_train).predict(X_test)\n",
        "knn_10_predictions = knn_10.fit(X_train, y_train).predict(X_test)\n",
        "knn_20_predictions = knn_20.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Get an accuracy score for each of the models\n",
        "knn_5_accuracy = accuracy_score(y_test, knn_5_predictions)\n",
        "knn_10_accuracy = accuracy_score(y_test, knn_10_predictions)\n",
        "knn_20_accuracy = accuracy_score(y_test, knn_20_predictions)\n",
        "print(\"The accuracy of 5, 10, 20 neighbours was {}, {}, {}\".format(knn_5_accuracy, knn_10_accuracy, knn_20_accuracy))"
      ],
      "metadata": {
        "id": "A5BmaJtvhdvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Values**"
      ],
      "metadata": {
        "id": "9-L4bpoGhfyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Create a learning_rates list for the learning rates, and a results_list to hold the accuracy score of your predictions.\n",
        "Write a loop to create a GBM model for each learning rate mentioned and create predictions for each model.\n",
        "Save the learning rate and accuracy score to a results_list.\n",
        "Turn the results list into a DataFrame and print it out.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Set the learning rates & results storage\n",
        "learning_rates = [0.001,.01,.05,.1,.2,.5]\n",
        "results_list = []\n",
        "\n",
        "# Create the for loop to evaluate model predictions for each learning rate\n",
        "for learning_rate in learning_rates:\n",
        "    model = GradientBoostingClassifier(learning_rate=learning_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    # Save the learning rate and accuracy score\n",
        "    results_list.append([learning_rate, accuracy_score(y_test, predictions)])\n",
        "\n",
        "# Gather everything into a DataFrame\n",
        "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "QKTkN87_hkts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Create a list of 30 learning rates evenly spread between 0.01 and 2.\n",
        "Create a similar loop to last exercise but just save out accuracy scores to a list.\n",
        "Plot the learning rates against the accuracy score.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Set the learning rates & accuracies list\n",
        "learn_rates = np.linspace(.01, 2, num=30)\n",
        "accuracies = []\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rates:\n",
        "  \t# Create the model, predictions & save the accuracies as before\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    accuracies.append(accuracy_score(y_test, predictions))\n",
        "\n",
        "# Plot results\n",
        "plt.plot(learn_rates, accuracies)\n",
        "plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DjZPv7MNhopA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}